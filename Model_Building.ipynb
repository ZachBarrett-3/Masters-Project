{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy, torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import roc_auc_score,precision_score,f1_score,recall_score, accuracy_score, roc_curve, auc,average_precision_score, precision_recall_curve, precision_recall_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Make a list of column names\n",
    "cols = ['HR_1', 'Sp02_1', 'dias_1', 'sys_1', 'resp_1',\n",
    "       'HR_2', 'Sp02_2', 'dias_2', 'sys_2', 'resp_2',\n",
    "       'HR_3', 'Sp02_3', 'dias_3', 'sys_3', 'resp_3',\n",
    "       'HR_4', 'Sp02_4', 'dias_4', 'sys_4', 'resp_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"PATH/data/Cleaned_Vitals/train_data.csv\").values\n",
    "y_train = pd.read_csv(\"PATH/data/Cleaned_Vitals/train_results.csv\").values\n",
    "X_test = pd.read_csv(\"PATH/data/Cleaned_Vitals/test_data.csv\").values\n",
    "y_test = pd.read_csv(\"PATH/data/Cleaned_Vitals/test_results.csv\").values\n",
    "\n",
    "def visualize_tree(t, feature_names):\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plot_tree(t, feature_names=feature_names, filled=True, ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "#Build the first tree Model\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "visualize_tree(tree, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samp = []\n",
    "acc = []\n",
    "\n",
    "#See how min_samples_leaf impacts accuracy (with fixed max_depth)\n",
    "for i in range(5,30):\n",
    " dtree = DecisionTreeClassifier(max_depth=5, min_samples_leaf = i)\n",
    " dtree.fit(X_train, y_train)\n",
    " pred = dtree.predict(X_test)\n",
    " acc.append(accuracy_score(y_test, pred))\n",
    " min_samp.append(i)\n",
    "\n",
    "data = {'min_samp_leaf': min_samp, 'acc': acc}\n",
    "df = pd.DataFrame(data)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot('min_samp_leaf', 'acc', data=df)\n",
    "plt.xlabel('min_samp_leaf')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "#See how max_depth impacts accuracy\n",
    "max_depth = []\n",
    "acc2 = []\n",
    "for i in range(1,20):\n",
    " dtree = DecisionTreeClassifier(max_depth=i)\n",
    " dtree.fit(X_train, y_train)\n",
    " pred = dtree.predict(X_test)\n",
    " acc2.append(accuracy_score(y_test, pred))\n",
    " max_depth.append(i)\n",
    "\n",
    "data = {'max_depth': max_depth, 'acc': acc2}\n",
    "df2 = pd.DataFrame(data)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot('max_depth', 'acc', data=df2)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = []\n",
    "min_samp = []\n",
    "acc = []\n",
    "\n",
    "#Find the optimal combination of max_depth and min_samples_leaf\n",
    "for d in range(1,5):\n",
    "    for s in range(5,20):\n",
    "        tree = DecisionTreeClassifier(max_depth=d, min_samples_leaf = s)\n",
    "        tree.fit(X_train, y_train)    \n",
    "        predicted_m, probas_ls = [], []\n",
    "        predicted_m = tree.predict(X_test)\n",
    "        probas_ls = tree.predict_proba(X_test)\n",
    "        fpr_ls, tpr_ls, thresholds_ROC = roc_curve(y_test, probas_ls[:, 1])\n",
    "        roc_auc_ls = auc(fpr_ls, tpr_ls)\n",
    "        optimal_idx = np.argmax(tpr_ls - fpr_ls)\n",
    "        optimal_threshold = thresholds_ROC[optimal_idx]\n",
    "        sensitivity_ls = tpr_ls[optimal_idx]\n",
    "        specificity_ls = 1 - fpr_ls[optimal_idx]\n",
    "        data_pred = np.zeros(len(probas_ls[:, 1]))\n",
    "        data_pred[probas_ls[:, 1] >= optimal_threshold] = 1\n",
    "        accuracy_ls = accuracy_score(y_test, data_pred) \n",
    "        acc.append(accuracy_ls)\n",
    "        max_depth.append(d)\n",
    "        min_samp.append(s)\n",
    "\n",
    "print(\"Max_depth\")\n",
    "print(len(max_depth))     \n",
    "print(\"Min_samp\")\n",
    "print(len(min_samp))\n",
    "print(len(acc))\n",
    " \n",
    "data = {'max_depth': max_depth, 'min_samp' :min_samp, 'acc': acc}\n",
    "df2 = pd.DataFrame(data)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the desired tree Model\n",
    "tree = DecisionTreeClassifier(max_depth=3, min_samples_leaf = 7)\n",
    "tree.fit(X_train, y_train)\n",
    "visualize_tree(tree, cols)\n",
    "\n",
    "# Model Performance\n",
    "predicted_m, probas_ls = [], []\n",
    "predicted_m = tree.predict(X_test)\n",
    "probas_ls = tree.predict_proba(X_test)\n",
    "fpr_ls, tpr_ls, thresholds_ROC = roc_curve(y_test, probas_ls[:, 1])\n",
    "roc_auc_ls = auc(fpr_ls, tpr_ls)\n",
    "optimal_idx = np.argmax(tpr_ls - fpr_ls)\n",
    "optimal_threshold = thresholds_ROC[optimal_idx]\n",
    "sensitivity_ls = tpr_ls[optimal_idx]\n",
    "specificity_ls = 1 - fpr_ls[optimal_idx]\n",
    "data_pred = np.zeros(len(probas_ls[:, 1]))\n",
    "data_pred[probas_ls[:, 1] >= optimal_threshold] = 1\n",
    "accuracy_ls = accuracy_score(y_test, data_pred)\n",
    "F1_ls = f1_score(y_test, data_pred)\n",
    "pr_each = average_precision_score(y_test, probas_ls[:, 1])\n",
    "precision_ls = precision_score(y_test, data_pred)\n",
    "\n",
    "print(\"AUC:\", round(100*roc_auc_ls,1), \n",
    "      \"\\nAccuracy:\", round(100*accuracy_ls, 1))\n",
    "\n",
    "# ROC curve\n",
    "plt.title('ROC Curve of Tree Model')\n",
    "plt.plot(fpr_ls, tpr_ls, 'b', label = 'AUC = %0.3f' % roc_auc_ls)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Save tpr and fpr to make a comparative roc curve\n",
    "fpr_tree = fpr_ls\n",
    "tpr_tree = tpr_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a 1-depth decision tree model\n",
    "tree = DecisionTreeClassifier(max_depth=1)\n",
    "tree.fit(X_train, y_train)\n",
    "visualize_tree(tree, cols)\n",
    "\n",
    "\n",
    "# Model Performance\n",
    "predicted_m, probas_ls = [], []\n",
    "predicted_m = tree.predict(X_test)\n",
    "probas_ls = tree.predict_proba(X_test)\n",
    "fpr_ls, tpr_ls, thresholds_ROC = roc_curve(y_test, probas_ls[:, 1])\n",
    "roc_auc_ls = auc(fpr_ls, tpr_ls)\n",
    "optimal_idx = np.argmax(tpr_ls - fpr_ls)\n",
    "optimal_threshold = thresholds_ROC[optimal_idx]\n",
    "sensitivity_ls = tpr_ls[optimal_idx]\n",
    "specificity_ls = 1 - fpr_ls[optimal_idx]\n",
    "data_pred = np.zeros(len(probas_ls[:, 1]))\n",
    "data_pred[probas_ls[:, 1] >= optimal_threshold] = 1\n",
    "accuracy_ls = accuracy_score(y_test, data_pred)\n",
    "F1_ls = f1_score(y_test, data_pred)\n",
    "pr_each = average_precision_score(y_test, probas_ls[:, 1])\n",
    "precision_ls = precision_score(y_test, data_pred)\n",
    "\n",
    "print(\"AUC:\", round(100*roc_auc_ls,1), \n",
    "      \"\\nAccuracy:\", round(100*accuracy_ls, 1))\n",
    "\n",
    "# ROC curve\n",
    "plt.title('ROC Curve of One-Depth Tree')\n",
    "plt.plot(fpr_ls, tpr_ls, 'b', label = 'AUC = %0.3f' % roc_auc_ls)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Save tpr and fpr to make a comparative roc curve\n",
    "fpr_1d_tree = fpr_ls\n",
    "tpr_1d_tree = tpr_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"PATH/data/Cleaned_Vitals/scaled_train_data.csv\").values\n",
    "y_train = pd.read_csv(\"PATH/data/Cleaned_Vitals/train_results.csv\").values\n",
    "X_test = pd.read_csv(\"PATH/data/Cleaned_Vitals/scaled_test_data.csv\").values\n",
    "y_test = pd.read_csv(\"PATH/data/Cleaned_Vitals/test_results.csv\").values\n",
    "\n",
    "# Define the MLPClassifier model\n",
    "model = make_pipeline(MLPClassifier(hidden_layer_sizes=(128,128, 128), activation='relu', solver='adam', max_iter=1000, batch_size=32))\n",
    "y_train = y_train.reshape(y_train.shape[0])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model Performance\n",
    "predicted_m, probas_ls = [], []\n",
    "predicted_m = model.predict(X_test)\n",
    "probas_ls = model.predict_proba(X_test)\n",
    "fpr_ls, tpr_ls, thresholds_ROC = roc_curve(y_test, probas_ls[:, 1])\n",
    "roc_auc_ls = auc(fpr_ls, tpr_ls)\n",
    "optimal_idx = np.argmax(tpr_ls - fpr_ls)\n",
    "optimal_threshold = thresholds_ROC[optimal_idx]\n",
    "sensitivity_ls = tpr_ls[optimal_idx]\n",
    "specificity_ls = 1 - fpr_ls[optimal_idx]\n",
    "data_pred = np.zeros(len(probas_ls[:, 1]))\n",
    "data_pred[probas_ls[:, 1] >= optimal_threshold] = 1\n",
    "accuracy_ls = accuracy_score(y_test, data_pred)\n",
    "F1_ls = f1_score(y_test, data_pred)\n",
    "pr_each = average_precision_score(y_test, probas_ls[:, 1])\n",
    "precision_ls = precision_score(y_test, data_pred)\n",
    "\n",
    "print(\"AUC:\", round(100*roc_auc_ls,1), \n",
    "      \"\\nAccuracy:\", round(100*accuracy_ls, 1))\n",
    "\n",
    "# ROC curve\n",
    "plt.title('ROC Curve for MLP Classifier')\n",
    "plt.plot(fpr_ls, tpr_ls, 'b', label = 'AUC = %0.3f' % roc_auc_ls)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Save tpr and fpr to make a comparative roc curve\n",
    "fpr_mlp = fpr_ls\n",
    "tpr_mlp = tpr_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "X_train = (pd.read_csv(\"PATH/data/Cleaned_Vitals/scaled_train_data.csv\")).values\n",
    "y_train = (pd.read_csv(\"PATH/data/Cleaned_Vitals/train_results.csv\")).values\n",
    "X_test = (pd.read_csv(\"PATH/data/Cleaned_Vitals/scaled_test_data.csv\")).values\n",
    "y_test = (pd.read_csv(\"PATH/data/Cleaned_Vitals/test_results.csv\")).values\n",
    "\n",
    "# Reshape the data to have a shape of (batch_size, sequence_length, input_size)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_torch = torch.from_numpy(X_train).float()\n",
    "y_train_torch = torch.from_numpy(y_train).float()\n",
    "X_test_torch = torch.from_numpy(X_test).float()\n",
    "y_test_torch = torch.from_numpy(y_test).float()\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        with torch.no_grad():\n",
    "            output = self(x)\n",
    "            return torch.sigmoid(output)\n",
    "\n",
    "# Define the PyTorch model and optimizer\n",
    "model = LSTMClassifier(input_size=X_train.shape[2], hidden_size=32, output_size=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_torch)\n",
    "    loss = criterion(output.view(-1), y_train_torch.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "with torch.no_grad():\n",
    "    output = model(X_test_torch)\n",
    "    predictions = (torch.sigmoid(output) >= 0.5).float()\n",
    "\n",
    "# Make predictions on the test set\n",
    "predicted_m, probas_ls = [], []\n",
    "predicted_m = np.round(y_pred)\n",
    "probas_ls = model.predict_proba(X_test_torch).numpy()\n",
    "fpr_ls, tpr_ls, thresholds_ROC = roc_curve(y_test, probas_ls)\n",
    "roc_auc_ls = auc(fpr_ls, tpr_ls)\n",
    "optimal_idx = np.argmax(tpr_ls - fpr_ls)\n",
    "optimal_threshold = thresholds_ROC[optimal_idx]\n",
    "data_pred = np.zeros(len(probas_ls))\n",
    "#print(probas_ls)\n",
    "#print(optimal_threshold)\n",
    "for i in range(len(probas_ls)):\n",
    "    if probas_ls[i] >= optimal_threshold:\n",
    "        data_pred[i] = 1\n",
    "accuracy_lstm = accuracy_score(y_test, data_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"AUC:\", roc_auc_ls)\n",
    "print(\"Accuracy:\", accuracy_lstm)\n",
    "\n",
    "# ROC curve\n",
    "fpr_lstm = fpr_ls\n",
    "tpr_lstm = tpr_ls\n",
    "\n",
    "plt.title('ROC Curve for LSTM Model')\n",
    "plt.plot(fpr_ls, tpr_ls, 'b', label = 'AUC = %0.3f' % auc_lstm)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0).clf()\n",
    "\n",
    "plt.plot(fpr_tree,tpr_tree,label=\"Decision Tree\")\n",
    "plt.plot(fpr_1d_tree,tpr_1d_tree,label=\"One-Depth Decision Tree\")\n",
    "plt.plot(fpr_mlp,tpr_mlp,label=\"MLP\")\n",
    "plt.plot(fpr_lstm,tpr_lstm,label=\"LSTM\")\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Model ROC Curves')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
